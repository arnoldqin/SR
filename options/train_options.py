from .base_options import BaseOptions


class TrainOptions(BaseOptions):
    def initialize(self):
        BaseOptions.initialize(self)
        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')
        self.parser.add_argument('--print_freq', type=int, default=10, help='frequency of showing training results on console')
        self.parser.add_argument('--save_latest_freq', type=int, default=2500, help='frequency of saving the latest results')
        self.parser.add_argument('--save_epoch_freq', type=int, default=10, help='frequency of saving checkpoints at the end of epochs')
        self.parser.add_argument('--eval_freq', type=int, default=2500, help='frequency of eval')
        self.parser.add_argument('--alpha_epoch', type=int, default=10, help='frequency of eval')
        self.parser.add_argument('--eval_batch', type=int, default=1, help='batchsize of eval')
        self.parser.add_argument('--update_D', type=int, default=0, help='batchsize of eval')
        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--toy_data', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--eval_to_dis', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--aux', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--d_lr2', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--one_side', action='store_true', help='continue training: load the latest model')
        self.parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')
        self.parser.add_argument('--load_path', type=str, default='', help='train, val, test, etc')
        self.parser.add_argument('--aux_loss', type=str, default='', help='train, val, test, etc')
        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')
        self.parser.add_argument('--gan', type=str, default='lsgan', help='train, val, test, etc')
        self.parser.add_argument('--gp', type=str, default='dragan', help='train, val, test, etc')
        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')
        self.parser.add_argument('--weight_adv', nargs='+')
        self.parser.add_argument('--weight_rec', nargs='+')
        self.parser.add_argument('--niter', type=int, default=25, help='# of iter at starting learning rate')
        self.parser.add_argument('--niter_decay', type=int, default=25, help='# of iter to linearly decay learning rate to zero')
        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')
        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')
        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')
        self.parser.add_argument('--log_grad', action='store_true', help='print gradient norm in log')
        self.parser.add_argument('--cyc_perc', action='store_true', help='print gradient norm in log')
        self.parser.add_argument('--style_layer', type=int, default=2, help='frequency of eval')
        self.parser.add_argument('--cont_layer', type=int, default=5, help='frequency of eval')
        self.parser.add_argument('--aff_aug', default='AB', help='use affine data agumentation in side (A|B|AB)')
        self.parser.add_argument('--enh_aug', default='', help='use affine data agumentation in side (A|B|AB)')
        self.parser.add_argument('--eval', action='store_true', help='eval')
        self.parser.add_argument('--train_epoch', type=int, default=20, help='')
        self.parser.add_argument('--trans_epoch', type=int, default=5, help='')
        self.parser.add_argument('--startSize', type=int, default=16, help='')
        self.parser.add_argument('--num_D', type=int, default=3, help='frequency of eval')
        self.parser.add_argument('--lambda_gp', type=float, default=10.0, help='weight for grad penalty')
        self.parser.add_argument('--lambda_cls', type=float, default=1.0, help='weight for classification loss')
        self.parser.add_argument('--lambda_adv', type=float, default=1.0, help='weight for adv loss')
	self.parser.add_argument('--lambda_AE', type=float, default=1.0, help='weight for AE loss')
        self.parser.add_argument('--lambda_AE_A', type=float, default=1.0, help='weight fro AE loss for G_A')
        self.parser.add_argument('--lambda_adv_pre', type=float, default=1.0, help='weight for first stack adv loss')
        self.parser.add_argument('--lambda_rec', type=float, default=10.0, help='weight for cycle loss')
        self.parser.add_argument('--lambda_rec_pre', type=float, default=10.0, help='weight for first stack cycle loss')
        self.parser.add_argument('--lambda_color_mean', type=float, default=0.0, help='weight')
        self.parser.add_argument('--lambda_color_sig_mean', type=float, default=0.0, help='weight')
        self.parser.add_argument('--lambda_style', type=float, default=0.0, help='weight')
        self.parser.add_argument('--lambda_color_var', type=float, default=5.0, help='weight')
        self.parser.add_argument('--lambda_content', type=float, default=0.0, help='weight')
        self.parser.add_argument('--lambda_content_l1', type=float, default=0.0, help='weight')
        self.parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')
        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')
        self.parser.add_argument('--lr_policy', type=str, default='lambda', help='learning rate policy: lambda|step|plateau')
        self.parser.add_argument('--lr_decay_iters', type=int, default=100, help='multiply by a gamma every lr_decay_iters iterations')
        self.parser.add_argument('--identity', type=float, default=0.0, help='use identity mapping. Setting identity other than 1 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set optidentity = 0.1')
        self.parser.add_argument('--scale', type=float, default=0, help='scale augmentation. [1-scale, 1+scale]')
        self.parser.add_argument('--l_fea_w', type=float, default=1, help='weigt of feature loss')
	self.parser.add_argument('--cri_fea', action='store_true', help='if true,use feature loss')
	self.isTrain = True
